{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":251556518,"sourceType":"kernelVersion"},{"sourceId":251556987,"sourceType":"kernelVersion"},{"sourceId":251628973,"sourceType":"kernelVersion"},{"sourceId":251629809,"sourceType":"kernelVersion"},{"sourceId":260430193,"sourceType":"kernelVersion"},{"sourceId":278121360,"sourceType":"kernelVersion"},{"sourceId":281344782,"sourceType":"kernelVersion"}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nfrom transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n\ndef get_model_pipeline(model_path):\n    \"\"\"\n    Loads the model directly from the specified path.\n    \"\"\"\n    if not os.path.exists(model_path):\n        raise FileNotFoundError(f\"Path {model_path} does not exist.\")\n    \n    print(f\"Loading model from: {model_path}\")\n\n    # Load Tokenizer and Model\n    try:\n        tokenizer = AutoTokenizer.from_pretrained(model_path)\n        model = AutoModelForTokenClassification.from_pretrained(model_path)\n    except OSError as e:\n        print(f\"Error loading model. Ensure 'config.json' and 'pytorch_model.bin' (or safetensors) exist in {model_path}\")\n        raise e\n    \n    # Create Pipeline\n    return pipeline('ner', model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-25T16:48:09.236255Z","iopub.execute_input":"2025-11-25T16:48:09.236612Z","iopub.status.idle":"2025-11-25T16:48:09.244192Z","shell.execute_reply.started":"2025-11-25T16:48:09.236583Z","shell.execute_reply":"2025-11-25T16:48:09.242805Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import re\n\ndef process_text(text, nlp_pipeline):\n    \"\"\"\n    1. Identify 'Atomic Tokens' using regex:\n       - Defined as text NOT separated by whitespace AND NOT separated by brackets [ ].\n    2. If the model finds ANY entity inside an atomic token, the WHOLE token is selected.\n    3. Priority: IPAddress > DNSName.\n    4. Merge adjacent tokens if they share the same label.\n    \"\"\"\n    # 1. Run raw inference\n    raw_results = nlp_pipeline(text)\n    \n    # 2. Identify \"Physical Tokens\" (sequences excluding whitespace and brackets)\n    # Regex: [^\\[\\]\\s]+ matches runs of characters that are NOT [ or ] or whitespace\n    physical_tokens = [match for match in re.finditer(r'[^\\[\\]\\s]+', text)]\n    \n    atomic_entities = []\n\n    # Step A: Quantize predictions to Physical Tokens\n    for pt in physical_tokens:\n        t_start, t_end = pt.span()\n        \n        # Find all raw NER predictions that overlap with this physical token\n        matches = [\n            r for r in raw_results \n            if r['start'] < t_end and r['end'] > t_start\n        ]\n        \n        if not matches:\n            continue\n\n        # Determine the Label for this physical token\n        labels = set(m['entity_group'] for m in matches)\n        \n        # Priority Rule 1: IPAddress > DNSName\n        if 'IPAddress' in labels and 'DNSName' in labels:\n            chosen_label = 'IPAddress'\n        else:\n            # Priority Rule 2: First detected part wins\n            matches.sort(key=lambda x: x['start'])\n            chosen_label = matches[0]['entity_group']\n        \n        # Calculate average confidence\n        avg_score = sum(float(m['score']) for m in matches) / len(matches)\n        \n        atomic_entities.append({\n            \"label\": chosen_label,\n            \"text\": text[t_start:t_end],\n            \"start\": t_start,\n            \"end\": t_end,\n            \"confidence\": avg_score\n        })\n\n    # Step B: Merge adjacent Atomic Entities\n    # (e.g., \"Jan\" + \"21\" -> \"Jan 21\")\n    if not atomic_entities:\n        return []\n        \n    final_entities = [atomic_entities[0]]\n    \n    for curr in atomic_entities[1:]:\n        prev = final_entities[-1]\n        \n        # Check if they are neighbors (text between is whitespace or brackets)\n        text_between = text[prev['end']:curr['start']]\n        \n        # We only merge if the separator is pure whitespace\n        # (If the separator contains [ or ], we usually DO NOT merge, as per your request to treat them as new tokens)\n        is_pure_whitespace = text_between.strip() == '' and '[' not in text_between and ']' not in text_between\n        \n        if is_pure_whitespace and prev['label'] == curr['label']:\n            # Merge them\n            prev['end'] = curr['end']\n            prev['text'] = text[prev['start']:prev['end']]\n            prev['confidence'] = (prev['confidence'] + curr['confidence']) / 2\n        else:\n            final_entities.append(curr)\n\n    # Step C: Final Cleanup (Rounding)\n    for ent in final_entities:\n        ent['confidence'] = round(ent['confidence'] * 100, 2)\n        \n    return final_entities","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T17:05:54.483038Z","iopub.execute_input":"2025-11-25T17:05:54.483452Z","iopub.status.idle":"2025-11-25T17:05:54.496034Z","shell.execute_reply.started":"2025-11-25T17:05:54.483425Z","shell.execute_reply":"2025-11-25T17:05:54.494831Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"# roberta-large","metadata":{}},{"cell_type":"code","source":"# 1. Initialize Pipeline\n# Point directly to your Kaggle input directory\nmodel_path = '/kaggle/input/hf-ner-uk-garawise-roberta-large/results/checkpoint-2772'\nnlp = get_model_pipeline(model_path) \n\n# 2. Define your text\ntext = \"Jan 21 17:36:40 dnsmasq[3468]: query[AAAA] de-lcs.naver.com.akadns.net from 10.143.1.78\"\n\n# 3. Get Results\nentities = process_text(text, nlp)\n\n# 4. View Results\nfor ent in entities:\n    print(f\"[{ent['label']}] {ent['text']} (Conf: {ent['confidence']}%)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T17:05:55.542163Z","iopub.execute_input":"2025-11-25T17:05:55.542940Z","iopub.status.idle":"2025-11-25T17:05:56.557328Z","shell.execute_reply.started":"2025-11-25T17:05:55.542909Z","shell.execute_reply":"2025-11-25T17:05:56.555936Z"}},"outputs":[{"name":"stdout","text":"Loading model from: /kaggle/input/hf-ner-uk-garawise-roberta-large/results/checkpoint-2772\n","output_type":"stream"},{"name":"stderr","text":"Device set to use cpu\n","output_type":"stream"},{"name":"stdout","text":"[DateTime] Jan 21 17:36:40 (Conf: 100.0%)\n[Action] dnsmasq (Conf: 98.14%)\n[Process] 3468 (Conf: 100.0%)\n[DNSName] de-lcs.naver.com.akadns.net (Conf: 83.32%)\n[IPAddress] 10.143.1.78 (Conf: 69.43%)\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"# xlm-roberta-large","metadata":{}},{"cell_type":"code","source":"# 1. Initialize Pipeline\n# Point directly to your Kaggle input directory\nmodel_path = '/kaggle/input/hf-ner-uk-garawise-xlm-roberta-large/results/checkpoint-12240'\nnlp = get_model_pipeline(model_path) \n\n# 2. Define your text\ntext = \"Jan 21 17:36:40 dnsmasq[3468]: query[AAAA] de-lcs.naver.com.akadns.net from 10.143.1.78\"\n\n# 3. Get Results\nentities = process_text(text, nlp)\n\n# 4. View Results\nfor ent in entities:\n    print(f\"[{ent['label']}] {ent['text']} (Conf: {ent['confidence']}%)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T17:06:12.640315Z","iopub.execute_input":"2025-11-25T17:06:12.640657Z","iopub.status.idle":"2025-11-25T17:06:14.259802Z","shell.execute_reply.started":"2025-11-25T17:06:12.640632Z","shell.execute_reply":"2025-11-25T17:06:14.258682Z"}},"outputs":[{"name":"stdout","text":"Loading model from: /kaggle/input/hf-ner-uk-garawise-xlm-roberta-large/results/checkpoint-12240\n","output_type":"stream"},{"name":"stderr","text":"Device set to use cpu\n","output_type":"stream"},{"name":"stdout","text":"[DateTime] Jan 21 17:36:40 (Conf: 100.0%)\n[Process] 3468 (Conf: 100.0%)\n[DNSName] de-lcs.naver.com.akadns.net (Conf: 89.46%)\n[IPAddress] 10.143.1.78 (Conf: 99.42%)\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"# roberta-base","metadata":{}},{"cell_type":"code","source":"# 1. Initialize Pipeline\n# Point directly to your Kaggle input directory\nmodel_path = '/kaggle/input/hf-ner-uk-garawise-roberta-base/results/checkpoint-2590'\nnlp = get_model_pipeline(model_path) \n\n# 2. Define your text\ntext = \"Jan 21 17:36:40 dnsmasq[3468]: query[AAAA] de-lcs.naver.com.akadns.net from 10.143.1.78\"\n\n# 3. Get Results\nentities = process_text(text, nlp)\n\n# 4. View Results\nfor ent in entities:\n    print(f\"[{ent['label']}] {ent['text']} (Conf: {ent['confidence']}%)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T17:06:34.305225Z","iopub.execute_input":"2025-11-25T17:06:34.305583Z","iopub.status.idle":"2025-11-25T17:06:35.172039Z","shell.execute_reply.started":"2025-11-25T17:06:34.305556Z","shell.execute_reply":"2025-11-25T17:06:35.171008Z"}},"outputs":[{"name":"stdout","text":"Loading model from: /kaggle/input/hf-ner-uk-garawise-roberta-base/results/checkpoint-2590\n","output_type":"stream"},{"name":"stderr","text":"Device set to use cpu\n","output_type":"stream"},{"name":"stdout","text":"[DateTime] Jan 21 17:36:40 (Conf: 100.0%)\n[DNSName] de-lcs.naver.com.akadns.net (Conf: 89.51%)\n[IPAddress] 10.143.1.78 (Conf: 100.0%)\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}